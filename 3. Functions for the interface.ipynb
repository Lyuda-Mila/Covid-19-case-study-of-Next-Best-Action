{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "np.random.seed(seed=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "action_rules_cases = pd.read_excel('Results/action_rules_cases.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best rule to decrease cases\n",
    "\n",
    "def get_best_rule_cases(c1,c2,c3,c4,c5,c6,c7,c8,h1):\n",
    "    c1_init = action_rules_cases['c1_init']\n",
    "    c2_init = action_rules_cases['c2_init']\n",
    "    c3_init = action_rules_cases['c3_init']\n",
    "    c4_init = action_rules_cases['c4_init']\n",
    "    c5_init = action_rules_cases['c5_init']\n",
    "    c6_init = action_rules_cases['c6_init']\n",
    "    c7_init = action_rules_cases['c7_init']\n",
    "    c8_init = action_rules_cases['c8_init']\n",
    "    h1_init = action_rules_cases['h1_init']\n",
    "    difference = []\n",
    "    for i in range(action_rules_cases.shape[0]):\n",
    "        d = 0\n",
    "        if c1_init[i]!=-1:\n",
    "            d = d+abs(c1_init[i]-c1)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c2_init[i]!=-1:\n",
    "            d = d+abs(c2_init[i]-c2)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c3_init[i]!=-1:\n",
    "            d = d+abs(c3_init[i]-c3)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c4_init[i]!=-1:\n",
    "            d = d+abs(c4_init[i]-c4)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c5_init[i]!=-1:\n",
    "            d = d+abs(c5_init[i]-c5)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c6_init[i]!=-1:\n",
    "            d = d+abs(c6_init[i]-c6)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c7_init[i]!=-1:\n",
    "            d = d+abs(c7_init[i]-c7)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c8_init[i]!=-1:\n",
    "            d = d+abs(c8_init[i]-c8)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if h1_init[i]!=-1:\n",
    "            d = d+abs(h1_init[i]-h1)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        difference.append(d)\n",
    "    min_d = min(difference)\n",
    "    action_rules_cases_mindiff = action_rules_cases[difference==min_d].sort_values(by = 'confidence', ascending = False)\n",
    "    max_conf = action_rules_cases_mindiff['confidence'].max()\n",
    "    best_rule = action_rules_cases_mindiff[action_rules_cases_mindiff['confidence'] == max_conf]\n",
    "    closest_state_str = \"The closest state: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={}. \".\\\n",
    "        format(best_rule.replace(-1, 'empty' )['c1_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c2_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c3_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c4_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c5_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c6_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c7_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c8_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['h1_init'].values[0])\n",
    "    res = []\n",
    "    res.append(closest_state_str)\n",
    "    res.append(\"Action Rule: \" +  best_rule['pretty_rule'].values[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The closest state: C1=empty, C2=0, C3=empty, C4=empty, C5=0, C6=0, C7=0, C8=1, H1=2. ',\n",
       " \"Action Rule: If attribute 'C5_Close public transport' value '0.0' is changed to '1.0', attribute 'C6_Stay at home requirements' value '0.0' is changed to '2.0', attribute 'H1_Public information campaigns' value '2.0' remains the same, attribute 'C2_Workplace closing' value '0.0' is changed to '3.0', attribute 'C7_Restrictions on internal movement' value '0.0' is changed to '2.0', attribute 'C8_International travel controls' value '1.0' is changed to '0.0', then 'ConfirmedCasesPctChangeWeekly16Flag' value '1.0' is changed to '0.0' with support: 0.01082629381493349, confidence: 0.7841424682395643 and uplift: 0.008751488391821383.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_rule_cases(0,0,1,3,0,0,0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "action_rules_deaths = pd.read_excel('Results/action_rules_deaths.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best rule to decrease deaths\n",
    "\n",
    "def get_best_rule_deaths(c1,c2,c3,c4,c5,c6,c7,c8,h1):\n",
    "\n",
    "    c1_init = action_rules_deaths['c1_init']\n",
    "    c2_init = action_rules_deaths['c2_init']\n",
    "    c3_init = action_rules_deaths['c3_init']\n",
    "    c4_init = action_rules_deaths['c4_init']\n",
    "    c5_init = action_rules_deaths['c5_init']\n",
    "    c6_init = action_rules_deaths['c6_init']\n",
    "    c7_init = action_rules_deaths['c7_init']\n",
    "    c8_init = action_rules_deaths['c8_init']\n",
    "    h1_init = action_rules_deaths['h1_init']\n",
    "    difference = []\n",
    "    for i in range(action_rules_deaths.shape[0]):\n",
    "        d = 0\n",
    "        if c1_init[i]!=-1:\n",
    "            d = d+abs(c1_init[i]-c1)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c2_init[i]!=-1:\n",
    "            d = d+abs(c2_init[i]-c2)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c3_init[i]!=-1:\n",
    "            d = d+abs(c3_init[i]-c3)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c4_init[i]!=-1:\n",
    "            d = d+abs(c4_init[i]-c4)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c5_init[i]!=-1:\n",
    "            d = d+abs(c5_init[i]-c5)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c6_init[i]!=-1:\n",
    "            d = d+abs(c6_init[i]-c6)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c7_init[i]!=-1:\n",
    "            d = d+abs(c7_init[i]-c7)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if c8_init[i]!=-1:\n",
    "            d = d+abs(c8_init[i]-c8)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        if h1_init[i]!=-1:\n",
    "            d = d+abs(h1_init[i]-h1)\n",
    "        else:\n",
    "            d = d + 1\n",
    "        difference.append(d)\n",
    "    min_d = min(difference)\n",
    "    action_rules_deaths_mindiff = action_rules_deaths[difference==min_d].sort_values(by = 'confidence', ascending = False)\n",
    "    max_conf = action_rules_deaths_mindiff['confidence'].max()\n",
    "    best_rule = action_rules_deaths_mindiff[action_rules_deaths_mindiff['confidence'] == max_conf]\n",
    "    closest_state_str = \"The closest state: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={}. \".\\\n",
    "        format(best_rule.replace(-1, 'empty' )['c1_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c2_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c3_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c4_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c5_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c6_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c7_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['c8_init'].values[0], \\\n",
    "        best_rule.replace(-1, 'empty' )['h1_init'].values[0])\n",
    "    res = []\n",
    "    res.append(closest_state_str)\n",
    "    res.append(\"Action Rule: \" +  best_rule['pretty_rule'].values[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The closest state: C1=0, C2=0, C3=empty, C4=empty, C5=empty, C6=0, C7=0, C8=0, H1=2. ',\n",
       " \"Action Rule: If attribute 'C6_Stay at home requirements' value '0.0' is changed to '2.0', attribute 'C1_School closing' value '0.0' is changed to '3.0', attribute 'H1_Public information campaigns' value '2.0' remains the same, attribute 'C2_Workplace closing' value '0.0' is changed to '3.0', attribute 'C7_Restrictions on internal movement' value '0.0' is changed to '2.0', attribute 'C8_International travel controls' value '0.0' remains the same, then 'ConfirmedDeathsPctChangeWeekly30Flag' value '1.0' is changed to '0.0' with support: 0.01335081075832605, confidence: 0.8260537293154873 and uplift: 0.011950197094106657.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_rule_deaths(0,1,2,4,1,0,0,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning. Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "qtable_cases = pd.read_excel('Results/qtable_cases.xlsx', converters={'Unnamed: 0':str})\n",
    "qtable_cases.index = qtable_cases['Unnamed: 0']\n",
    "qtable_cases = qtable_cases.drop(columns = ['Unnamed: 0'],axis = 1)\n",
    "qtable_cases = qtable_cases.replace(0.0, np.nan)\n",
    "qtable_cases = qtable_cases.dropna(axis=0,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cases\n",
    "def get_best_action_rl_cases(с1,c2,c3,c4,c5,c6,c7,c8,h1):\n",
    "    st = str(с1) + str(c2) + str(c3)  + str(c4)  + str(c5)  + str(c6)  + str(c7)  + str(c8)  + str(h1)\n",
    "    difference = []\n",
    "    if st in qtable_cases.index:\n",
    "        max_reward = qtable_cases.loc[st, :].max() \n",
    "        next_action = qtable_cases.loc[st, :][qtable_cases.loc[st, :] == max_reward].index.values[0]\n",
    "        result_str = \"Recommended action: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={} with expected reward={}\".format(next_action[0], next_action[1], next_action[2], next_action[3], next_action[4], next_action[5], next_action[6], next_action[7], next_action[8], max_reward)\n",
    "        res = []\n",
    "        res.append(\"\")\n",
    "        res.append(result_str)\n",
    "    else:\n",
    "        for i in range(len(qtable_cases.index)):\n",
    "            d = 0\n",
    "            d = d+abs(int(qtable_cases.index[i][0])-с1)\n",
    "            d = d+abs(int(qtable_cases.index[i][1])-c2)\n",
    "            d = d+abs(int(qtable_cases.index[i][2])-c3)\n",
    "            d = d+abs(int(qtable_cases.index[i][3])-c4)\n",
    "            d = d+abs(int(qtable_cases.index[i][4])-c5)\n",
    "            d = d+abs(int(qtable_cases.index[i][5])-c6)\n",
    "            d = d+abs(int(qtable_cases.index[i][6])-c7)\n",
    "            d = d+abs(int(qtable_cases.index[i][7])-c8)\n",
    "            d = d+abs(int(qtable_cases.index[i][8])-h1)\n",
    "            difference.append(d)\n",
    "        min_d = min(difference)\n",
    "        cond = pd.DataFrame(difference)[0]==min_d\n",
    "        cond.index = qtable_cases.index\n",
    "        qtable_cases_mindiff = qtable_cases[cond]\n",
    "        max_reward = qtable_cases_mindiff.max().max()\n",
    "        next_action = qtable_cases_mindiff.max()[qtable_cases_mindiff.max()==max_reward].index[0]\n",
    "        closest_state = qtable_cases_mindiff.loc[:, next_action][qtable_cases_mindiff.loc[:, next_action]==max_reward].index[0]\n",
    "        next_action_str = \"Recommended action: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={} with expected reward={}\".format(next_action[0], next_action[1], next_action[2], next_action[3], next_action[4], next_action[5], next_action[6], next_action[7], next_action[8], max_reward)\n",
    "        closest_state_str = \"The closest state: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={}. \".format(closest_state[0], closest_state[1], closest_state[2], closest_state[3], closest_state[4], closest_state[5], closest_state[6], closest_state[7], closest_state[8])\n",
    "        res = []\n",
    "        res.append(closest_state_str)\n",
    "        res.append(next_action_str)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The closest state: C1=0, C2=0, C3=0, C4=2, C5=0, C6=0, C7=0, C8=0, H1=2. ',\n",
       " 'Recommended action: C1=0, C2=0, C3=0, C4=2, C5=0, C6=0, C7=0, C8=3, H1=2 with expected reward=-0.2358870967741936']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_action_rl_cases(0,0,0,3,0,0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "qtable_deaths = pd.read_excel('Results/qtable_deaths.xlsx', converters={'Unnamed: 0':str})\n",
    "qtable_deaths.index = qtable_deaths['Unnamed: 0']\n",
    "qtable_deaths = qtable_deaths.drop(columns = ['Unnamed: 0'],axis = 1)\n",
    "qtable_deaths = qtable_deaths.replace(0.0, np.nan)\n",
    "qtable_deaths = qtable_deaths.dropna(axis=0,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deaths\n",
    "def get_best_action_rl_deaths(с1,c2,c3,c4,c5,c6,c7,c8,h1):\n",
    "    st = str(с1) + str(c2) + str(c3)  + str(c4)  + str(c5)  + str(c6)  + str(c7)  + str(c8)  + str(h1)\n",
    "    difference = []\n",
    "    if st in qtable_deaths.index:\n",
    "        max_reward = qtable_deaths.loc[st, :].max() \n",
    "        next_action = qtable_deaths.loc[st, :][qtable_deaths.loc[st, :] == max_reward].index.values[0]\n",
    "        result_str = \"Recommended action: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={} with expected reward={}\".format(next_action[0], next_action[1], next_action[2], next_action[3], next_action[4], next_action[5], next_action[6], next_action[7], next_action[8], max_reward)\n",
    "        res = []\n",
    "        res.append(\"\")\n",
    "        res.append(result_str)\n",
    "    else:\n",
    "        for i in range(len(qtable_deaths.index)):\n",
    "            d = 0\n",
    "            d = d+abs(int(qtable_deaths.index[i][0])-с1)\n",
    "            d = d+abs(int(qtable_deaths.index[i][1])-c2)\n",
    "            d = d+abs(int(qtable_deaths.index[i][2])-c3)\n",
    "            d = d+abs(int(qtable_deaths.index[i][3])-c4)\n",
    "            d = d+abs(int(qtable_deaths.index[i][4])-c5)\n",
    "            d = d+abs(int(qtable_deaths.index[i][5])-c6)\n",
    "            d = d+abs(int(qtable_deaths.index[i][6])-c7)\n",
    "            d = d+abs(int(qtable_deaths.index[i][7])-c8)\n",
    "            d = d+abs(int(qtable_deaths.index[i][8])-h1)\n",
    "            difference.append(d)\n",
    "        min_d = min(difference)\n",
    "        cond = pd.DataFrame(difference)[0]==min_d\n",
    "        cond.index = qtable_deaths.index\n",
    "        qtable_deaths_mindiff = qtable_deaths[cond]\n",
    "        max_reward = qtable_deaths_mindiff.max().max()\n",
    "        next_action = qtable_deaths_mindiff.max()[qtable_deaths_mindiff.max()==max_reward].index[0]\n",
    "        closest_state = qtable_deaths_mindiff.loc[:, next_action][qtable_deaths_mindiff.loc[:, next_action]==max_reward].index[0]\n",
    "        next_action_str = \"Recommended action: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={} with expected reward={}\".format(next_action[0], next_action[1], next_action[2], next_action[3], next_action[4], next_action[5], next_action[6], next_action[7], next_action[8], max_reward)\n",
    "        closest_state_str = \"The closest state: C1={}, C2={}, C3={}, C4={}, C5={}, C6={}, C7={}, C8={}, H1={}. \".format(closest_state[0], closest_state[1], closest_state[2], closest_state[3], closest_state[4], closest_state[5], closest_state[6], closest_state[7], closest_state[8])\n",
    "        result_str = closest_state_str+next_action_str\n",
    "        res = []\n",
    "        res.append(closest_state_str)\n",
    "        res.append(next_action_str)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Recommended action: C1=0, C2=1, C3=2, C4=4, C5=1, C6=0, C7=2, C8=0, H1=2 with expected reward=0.3571428571428572']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_action_rl_deaths(0,1,2,4,1,0,0,0,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
